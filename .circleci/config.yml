version: 2.1
orbs:
  slack: circleci/slack@4.1.1
  aws-eks: circleci/aws-eks@0.2.0
  aws-ecr: circleci/aws-ecr@3.1.0
  kubernetes: circleci/kubernetes@0.3.0

parameters:
  cluster-name:
    type: string
    default: "capstone-employee"

commands:
  destroy-environment:
    description: Destroy backend and frontend stacks.
    steps:      
      - run:
          name: Destroy environment
          when: on_fail
          command: |
            if ! [ -x "$(command -v aws)" ]; then
            pip install awscli
            else
            echo "AWS CLI already installed"
            fi
            aws s3 rm s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7} --recursive
            aws cloudformation delete-stack --stack-name frontend-${CIRCLE_WORKFLOW_ID:0:7}
            aws cloudformation delete-stack --stack-name backend-${CIRCLE_WORKFLOW_ID:0:7}  
  
  revert-migrations:
    description: Revert the last migration if successfully run in the current workflow.   
    steps:
      - run:
          name: Revert migrations
          when: on_fail
          command: |
            SUCCESS=$(curl -H "token: ${CIRCLE_WORKFLOW_ID:0:7}" \
            --request GET https://api.memstash.io/values/migration-${CIRCLE_WORKFLOW_ID:0:7})
            echo "************** SUCCESS = $SUCCESS"
            if(( $SUCCESS==1 )); 
            then
             cd backend
             npm install
             npm run migrations:revert
            fi      
            
jobs:
  build-frontend:
    docker:
      - image: circleci/node:13.8.0
        environment:
          baseUrl: http://local:9095
    steps:
      - checkout
      - restore_cache:
          keys: 
            - frontend-build-${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: Build front-end
          command: |            
            cd angular8-crud-demo      
            npm install
            npm run build --prod 
      - save_cache:
          paths:
            - angular8-crud-demo/node_modules
            - angular8-crud-demo/dist
          key: frontend-build-${CIRCLE_WORKFLOW_ID:0:7}

  build-backend:
    docker:
      - image: circleci/openjdk:11-jdk        
    steps:
    - checkout
    - restore_cache:
        keys:
          - v1-dependencies-{{ checksum "springboot-crud-api/pom.xml" }}
          # fallback to using the latest cache if no exact match is found
          - v1-dependencies-    
    - run:
        name: Back-end build
        command: |
          cd springboot-crud-api
          echo 'export DATABASE_URL=jdbc:mysql://capstone.caejyuh3eggl.eu-west-1.rds.amazonaws.com:3306/capstone' >> $BASH_ENV
          echo 'export DATABASE_USER=admin' >> $BASH_ENV
          echo 'export DATABASE_PASSWORD=Capstone21' >> $BASH_ENV
          source $BASH_ENV     
          mvn clean install -DskipTests
    - save_cache:
          paths: 
            - ~/.m2
          key: v1-dependencies-{{ checksum "springboot-crud-api/pom.xml" }}
  
  test-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: 
            - frontend-build-${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: Test front-end
          no_output_timeout: 20m
          command: |
            cd angular8-crud-demo     
            npm run test
                
  test-backend:
    docker:
      - image: circleci/openjdk:11-jdk
    steps:
    - checkout
    - restore_cache:
        keys: 
          - v1-dependencies-{{ checksum "springboot-crud-api/pom.xml" }}
          # fallback to using the latest cache if no exact match is found
          - v1-dependencies-    
    - run:
        name: Test Back-end
        command: |
          cd springboot-crud-api
          mvn dependency:go-offline
          echo 'export DATABASE_URL=jdbc:mysql://capstone.caejyuh3eggl.eu-west-1.rds.amazonaws.com:3306/capstone' >> $BASH_ENV
          echo 'export DATABASE_USER=admin' >> $BASH_ENV
          echo 'export DATABASE_PASSWORD=Capstone21' >> $BASH_ENV
          source $BASH_ENV     
          mvn test
          
  scan-frontend:
    docker:
      - image: circleci/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: 
            - frontend-build-${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: Scan frontend
          command: |
            cd frontend
            npm update        
            npm audit fix --audit-level=critical

  scan-backend:
    docker:
      - image: 'circleci/openjdk:11-jdk'
    steps:
      - checkout
      - restore_cache:
          keys: 
            - v1-dependencies-{{ checksum "springboot-crud-api/pom.xml" }}
            # fallback to using the latest cache if no exact match is found
            - v1-dependencies- 
      - run:
          name: Analyze on SonarCloud
          command: |
            cd springboot-crud-api
            mvn dependency:go-offline        
            mvn verify sonar:sonar

   

  build_and_push:
    docker:
      - image: circleci/openjdk:11-jdk
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: Setup common environment variables
          command: |
            echo 'export ECR_REPOSITORY_NAME="${AWS_RESOURCE_NAME_PREFIX}"' >> $BASH_ENV
            echo 'export FULL_IMAGE_NAME="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${ECR_REPOSITORY_NAME}:latest"' >> $BASH_ENV
      - restore_cache:
          keys: 
            - v1-dependencies-{{ checksum "springboot-crud-api/pom.xml" }}
            # fallback to using the latest cache if no exact match is found
            - v1-dependencies- 
      - run:
          name: Install dependencies for AWS
          command: |
            sudo apt-get update
            sudo apt-get -y -qq install awscli
            sudo apt-get install python3-pip
            sudo pip3 install --upgrade awscli
      - run:
          name: Build image
          command: |
            cd springboot-crud-api
            mvn dependency:go-offline
            mvn package
            docker build -t $FULL_IMAGE_NAME .
      - run:
          name: Push image
          command: |
            eval $(aws ecr get-login --region $AWS_DEFAULT_REGION --no-include-email)
            docker push $FULL_IMAGE_NAME

  create-eks-cluster:
    executor: aws-eks/python3
    steps:
      - checkout
      - aws-eks/create-cluster:
          cluster-name: << pipeline.parameters.cluster-name >>
          aws-region: $AWS_DEFAULT_REGION
          nodegroup-name: ng-1
          node-type: t2.micro
          nodes: 1
          
  deploy-application:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster
        type: string
      docker-image-name:
        description: |
          Name of the docker image to be deployed
        type: string
      version-info:
        description: |
          App version information
        type: string
      aws-region:
        description: |
          AWS region
        type: string
        default: ""
    steps:
      - checkout
      - run:
          name: Setup common environment variables
          command: |
            echo 'export ECR_REPOSITORY_NAME="${AWS_RESOURCE_NAME_PREFIX}"' >> $BASH_ENV
            echo 'export FULL_IMAGE_NAME="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/${ECR_REPOSITORY_NAME}:latest"' >> $BASH_ENV
      - run:
          name: Create deployment manifest
          command: |
            # Replace the placeholders in the manifest with the intended values.
            # This is to avoid hardcoding the image name in the manifest, to make this
            # demo project more portable.
            BUILD_DATE=$(date '+%Y%m%d%H%M%S')
            cat springboot-crud-api/deployment.yml |\
               sed "s|DOCKER_IMAGE_NAME|$FULL_IMAGE_NAME|\
                g;s|BUILD_DATE_VALUE|$BUILD_DATE|g;s|VERSION_INFO_VALUE|\
                << parameters.version-info >>|g" > springboot-crud-api/deployment.yml
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: << parameters.cluster-name >>
          install-kubectl: true
          aws-region: $AWS_DEFAULT_REGION
      - kubernetes/create-or-update-resource:
          resource-file-path: "springboot-crud-api/deployment.yml"
          get-rollout-status: true
          resource-name: deployment/employeeapp
      - kubernetes/create-or-update-resource:
          resource-file-path: "springboot-crud-api/deployment.yml"


  test-application:
    executor: aws-eks/python3
    parameters:
      cluster-name:
        description: |
          Name of the EKS cluster
        type: string
      aws-region:
        description: |
          AWS region
        type: string
        default: ""
      expected-version-info:
        description: |
          Expected app version (this is used for testing that the
          correct version has been deployed)
        type: string
    steps:
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: << parameters.cluster-name >>
          install-kubectl: true
          aws-region: $AWS_DEFAULT_REGION
      - run:
          name: Wait for service to be ready
          command: |
            kubectl get pods
            kubectl get services
            sleep 30
            for attempt in {1..20}; do
              EXTERNAL_IP=$(kubectl get service employeeapp | awk '{print $4}' | tail -n1)
              echo "Checking external IP: ${EXTERNAL_IP}"
              if [ -n "${EXTERNAL_IP}" ] && [ -z $(echo "${EXTERNAL_IP}" | grep "pending") ]; then
                break
              fi
              echo "Waiting for external IP to be ready: ${EXTERNAL_IP}"
              sleep 10
            done
            sleep 180
            curl -s --retry 10 "http://$EXTERNAL_IP" | grep "<< parameters.expected-version-info >>"
 

workflows:
  default:
    jobs:      
      - build-frontend
      - build-backend
      #- test-frontend:
      #    requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      #- scan-backend:
       #   context: SonarCloud
        #  requires: [build-backend]
      - build_and_push:
          requires: [test-backend]
      #- create-eks-cluster:
       #   requires: [build_and_push]
      - deploy-application:
          cluster-name: "capstone-employee"
          aws-region: $AWS_DEFAULT_REGION
          docker-image-name: "${AWS_ECR_URL}/eks_orb_demo_app:${CIRCLE_SHA1}"
          version-info: "${CIRCLE_SHA1}"
          requires: [build_and_push]
      - test-application:
          name: test-application
          cluster-name: "capstone-employee"
          aws-region: $AWS_DEFAULT_REGION
          expected-version-info: "${CIRCLE_SHA1}"
          requires:
            - deploy-application